{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "azure_endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint=azure_endpoint, \n",
    "  api_key=api_key,\n",
    "  api_version=\"2024-02-01\"\n",
    ")\n",
    "\n",
    "CHAT_COMPLETIONS_MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Few Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòÇ,üíÄ,ü§£,üéâ,üîä\n"
     ]
    }
   ],
   "source": [
    "# Zero-shot classification\n",
    "system_prompt =\"\"\"Predict up to 5 emojis as a response to a text chat message. The output\n",
    "should only include emojis.\n",
    "\n",
    "input: The new visual design is blowing my mind ü§Ø\n",
    "output: ‚ûï,üíò, ‚ù§‚Äçüî•\n",
    "\n",
    "input: Well that looks great regardless\n",
    "output: ‚ù§Ô∏è,ü™Ñ\n",
    "\n",
    "input: Unfortunately this won't work\n",
    "output: üíî,üòî\n",
    "\n",
    "input: sounds good, I'll look into that\n",
    "output: üôè,üëç\n",
    "\n",
    "input: 10hr cut of jeff goldblum laughing URL\n",
    "output: üòÇ,üíÄ,‚ö∞Ô∏è\n",
    "\"\"\"\n",
    "user_prompt = \"(10hr cut of jeff goldblum laughing URL)\"\n",
    "response = client.chat.completions.create(\n",
    "    model=CHAT_COMPLETIONS_MODEL,\n",
    "    messages = [{\"role\":\"system\", \"content\":system_prompt},\n",
    "                {\"role\":\"user\",\"content\": user_prompt,}])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering Best Practices\n",
    "\n",
    "## Write clear instructions\n",
    "\n",
    "Examples:\n",
    "\n",
    "-----------------------\n",
    "Prompt:\n",
    "\n",
    "Write code to calculate the Fibonacci sequence.\n",
    "\n",
    "Better:\n",
    "\n",
    "Write a TypeScript function to efficiently calculate the Fibonacci sequence. Comment the code liberally to explain what each piece does and why it's written that way.\n",
    "\n",
    "----------------------\n",
    "\n",
    "Prompt:\n",
    "\n",
    "Summarize the meeting notes.\n",
    "\n",
    "Better:\n",
    "\n",
    "Summarize the meeting notes in a single paragraph. Then write a markdown list of the speakers and each of their key points. Finally, list the next steps or action items suggested by the speakers, if any.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Role Playing\n",
    "\n",
    "Examples:\n",
    "\n",
    "-----------------------\n",
    "\n",
    "System Message: When I ask for help to write something, you will reply with a document that contains at least one joke or playful comment in every paragraph.\n",
    "\n",
    "----------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment input text\n",
    "\n",
    "Examples:\n",
    "\n",
    "------------------------\n",
    "\n",
    "user message: Summarize the text delimited by triple quotes with a haiku.\n",
    "\n",
    "\"\"\"insert text here\"\"\"\n",
    "\n",
    "------------------------\n",
    "\n",
    "system message: You will be provided with a pair of articles (delimited with XML tags) about the same topic. First summarize the arguments of each article. Then indicate which of them makes a better argument and explain why.\n",
    "\n",
    "user message: \n",
    "\n",
    "\\<article> insert first article here \\</article>\n",
    "\n",
    "\\<article> insert second article here \\</article>\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain steps and processes to complete a task\n",
    "\n",
    "Examples:\n",
    "\n",
    "--------------------------------\n",
    "\n",
    "System Message:\n",
    "Use the following step-by-step instructions to respond to user inputs.\n",
    "\n",
    "Step 1 - The user will provide you with text in triple quotes. Summarize this text in one sentence with a prefix that says \"Summary: \".\n",
    "\n",
    "Step 2 - Translate the summary from Step 1 into Spanish, with a prefix that says \"Translation: \".\n",
    "\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Clasificaci√≥n de Emojis con Zero-shot\n",
    "Enunciado:\n",
    "Dado el siguiente texto, predice hasta 5 emojis que mejor representen la emoci√≥n o el tema del mensaje. Usa el modelo de Zero-shot para hacer la clasificaci√≥n.\n",
    "\n",
    "Texto: \"Estoy tan feliz que no puedo dejar de sonre√≠r.\"\n",
    "\n",
    "Resultado esperado: üòÑ,üòä,‚ú®,üåû,‚ù§Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòÅ,üéâ,üåà,‚ù§Ô∏è,‚ú®\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"Estoy tan feliz que no puedo dejar de sonre√≠r.\"\n",
    "response = client.chat.completions.create(\n",
    "    model=CHAT_COMPLETIONS_MODEL,\n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\":system_prompt},\n",
    "        {\"role\":\"user\",\"content\": user_prompt,}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Traducci√≥n de Resumen\n",
    "Enunciado:\n",
    "El siguiente texto es una transcripci√≥n de una reuni√≥n. Res√∫melo en una sola oraci√≥n, luego traduce ese resumen al ingl√©s.\n",
    "\n",
    "Texto:\n",
    "\"\"\"Hoy discutimos sobre la necesidad de mejorar la interfaz de usuario en el sitio web. Los participantes estuvieron de acuerdo en que se debe hacer m√°s intuitiva y accesible, especialmente para usuarios mayores. Tambi√©n se mencion√≥ la importancia de agregar soporte multiling√ºe.\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Se acord√≥ en la reuni√≥n la necesidad de mejorar la interfaz de usuario del sitio web para que sea m√°s intuitiva y accesible, especialmente para usuarios mayores, y de incorporar soporte multiling√ºe.\n",
      "Translation: It was agreed in the meeting on the need to improve the website's user interface to make it more intuitive and accessible, especially for older users, and to incorporate multilingual support.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"El siguiente texto es una transcripci√≥n de una reuni√≥n. Res√∫melo en una sola oraci√≥n.\"\"\"\n",
    "user_prompt = \"\"\"Hoy discutimos sobre la necesidad de mejorar la interfaz de usuario en el sitio web. Los participantes estuvieron de acuerdo en que se debe hacer m√°s intuitiva y accesible, especialmente para usuarios mayores. Tambi√©n se mencion√≥ la importancia de agregar soporte multiling√ºe.\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\":system_prompt},\n",
    "        {\"role\":\"user\",\"content\": user_prompt,}\n",
    "    ]\n",
    ")\n",
    "summary = response.choices[0].message.content\n",
    "print(f\"Summary: {summary}\")\n",
    "\n",
    "# Traducci√≥n al ingl√©s\n",
    "translation_prompt = f\"Traduce el siguiente resumen al Ingles: {summary}\"\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\":translation_prompt},\n",
    "    ]\n",
    ")\n",
    "print(f\"Translation: {response.choices[0].message.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Respuesta Autom√°tica con Role-playing\n",
    "Enunciado:\n",
    "Configura un modelo para responder a una solicitud de escritura, haciendo que la respuesta contenga un toque de humor. Usa la siguiente solicitud como ejemplo.\n",
    "\n",
    "Solicitud:\n",
    "\"Escribe una carta formal solicitando d√≠as de vacaciones.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tu Nombre]  \n",
      "[Tu Direcci√≥n]  \n",
      "[Ciudad, Estado, C√≥digo Postal]  \n",
      "[Tu Correo Electr√≥nico]  \n",
      "[Tu N√∫mero de Tel√©fono]  \n",
      "[Fecha]  \n",
      "\n",
      "[Nombre del Jefe o Supervisor]  \n",
      "[Nombre de la Empresa]  \n",
      "[Direcci√≥n de la Empresa]  \n",
      "[Ciudad, Estado, C√≥digo Postal]  \n",
      "\n",
      "Estimado/a [Nombre del Jefe o Supervisor]:  \n",
      "\n",
      "Espero que este mensaje lo/a encuentre con buen √°nimo y una taza de caf√© (o t√©) humeante a la mano, porque voy a necesitar un poco de esos buenos deseos para mi solicitud.  \n",
      "\n",
      "Me dirijo a usted para solicitar formalmente unos d√≠as de vacaciones, desde el [fecha de inicio] hasta el [fecha de finalizaci√≥n]. He estado trabajando arduamente y, como bien dice el refr√°n, ‚Äútodo trabajo y nada de diversi√≥n hace de [Tu Nombre] un/a... bueno, digamos que no soy el m√°s divertido del equipo\".  \n",
      "\n",
      "He planificado estas vacaciones con anticipaci√≥n para asegurarme de que mis responsabilidades est√©n cubiertas. Me comprometo a dejar todo en orden y disponible para que el equipo pueda avanzar sin problemas, porque, como dice mi planta de escritorio, ‚Äúla clave est√° en la planificaci√≥n‚Ä¶ y en el riego‚Äù.  \n",
      "\n",
      "Agradezco de antemano su comprensi√≥n y apoyo a esta solicitud. Espero poder recargar energ√≠as y regresar listo/a para impulsar ya no solo mis tareas, sino hasta la productividad del equipo, ¬°que no se diga que solo estuve tomando el sol!  \n",
      "\n",
      "Quedo a su disposici√≥n para discutir esta solicitud y coordinar cualquier detalle necesario.  \n",
      "\n",
      "Agradeci√©ndole de antemano su atenci√≥n, le env√≠o un cordial saludo (y un gui√±o en caso de que me d√© los d√≠as).  \n",
      "\n",
      "Atentamente,  \n",
      "[Tu Nombre]  \n",
      "[Tu Puesto]\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"Cuando te indique que escribas algo, responder√°s con el documento solilcitado, d√°ndole toques de humor como bromas o juegos de palabras.\"\"\"\n",
    "\n",
    "user_prompt = \"Escribe una carta formal solicitando d√≠as de vacaciones.\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=CHAT_COMPLETIONS_MODEL,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "              {\"role\": \"user\", \"content\": user_prompt}]\n",
    ")\n",
    "\n",
    "# Mostrar la respuesta generada\n",
    "print(response.choices[0].message.content)  # Ejemplo de salida: carta con broma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Segmentaci√≥n de Texto\n",
    "Enunciado:\n",
    "Segmenta un texto delimitado por comillas triples y luego trad√∫celo a otro idioma (por ejemplo, ingl√©s). Aplica el siguiente formato de entrada de texto y muestra c√≥mo lo har√≠as.\n",
    "\n",
    "Texto de Entrada:\n",
    "\"\"\"Hoy es un buen d√≠a para aprender nuevas cosas y mejorar nuestras habilidades. ¬°El futuro est√° lleno de oportunidades!\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Hoy es un buen d√≠a para aprender nuevas cosas y mejorar nuestras habilidades. ¬°El futuro est√° lleno de oportunidades!\"\n",
      "\n",
      "Segmentaci√≥n:\n",
      "1. Hoy es un buen d√≠a para aprender nuevas cosas.\n",
      "2. Mejorar nuestras habilidades.\n",
      "3. ¬°El futuro est√° lleno de oportunidades!\n",
      "\n",
      "Traducci√≥n al ingl√©s:\n",
      "1. Today is a good day to learn new things.\n",
      "2. Improve our skills.\n",
      "3. The future is full of opportunities!\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"Se te va a proporcionar un texto delimitado por comillas triples. Deber√°s segmentarlo y proporcionar una traducci√≥n al ingl√©s.\"\"\"\n",
    "user_prompt = \"\"\"Hoy es un buen d√≠a para aprender nuevas cosas y mejorar nuestras habilidades. ¬°El futuro est√° lleno de oportunidades!\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=CHAT_COMPLETIONS_MODEL,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "              {\"role\": \"user\", \"content\": user_prompt}]\n",
    ")\n",
    "\n",
    "# Mostrar la respuesta generada\n",
    "print(response.choices[0].message.content)  # Salida esperada: resumen en espa√±ol e ingl√©s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6: Predicci√≥n de Emojis con Zero-shot\n",
    "Enunciado:\n",
    "Realiza una clasificaci√≥n Zero-shot utilizando el modelo y predice hasta 5 emojis para el siguiente mensaje:\n",
    "\n",
    "Texto de entrada:\n",
    "\"Estoy muy cansado, pero contento con el trabajo que he hecho.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòåüí™üéâüåüüò¥\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"Predice hasta 5 emojis como respuesta a un mensaje de chat. La salida debe solo incluir emojis.\"\"\"\n",
    "user_prompt = \"Estoy muy cansado, pero contento con el trabajo que he hecho.\"\n",
    "response = client.chat.completions.create(\n",
    "    model=CHAT_COMPLETIONS_MODEL,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "              {\"role\": \"user\", \"content\": user_prompt}]\n",
    ")\n",
    "\n",
    "# Mostrar la respuesta generada\n",
    "print(response.choices[0].message.content)  # Ejemplo de salida: \"üòÖ,üí™,üëå\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 7: Predicci√≥n de Emojis con Few-shot Learning\n",
    "\n",
    "Enunciado:\n",
    "\n",
    "En este ejercicio utilizar√°s Few-shot learning con roles (system, user, assistant) para predecir emojis. En Few-shot learning, proporcionamos ejemplos espec√≠ficos de interacciones para que el modelo aprenda a generalizar la tarea con pocos ejemplos.\n",
    "\n",
    "Dado un conjunto de ejemplos de interacciones entre un usuario y un asistente, utiliza el modelo para predecir hasta 5 emojis para el siguiente mensaje:\n",
    "\n",
    "Mensaje: \"Estoy muy cansado, pero contento con el trabajo que he hecho.\"\n",
    "\n",
    "Devuelve solo los emojis, separados por comas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòå,üíº,üëç,üò¥\n"
     ]
    }
   ],
   "source": [
    "# Definir el prompt con Few-shot utilizando m√∫ltiples roles\n",
    "few_shot_prompt = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an assistant that predicts emojis based on user text.\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"Estoy muy feliz con mi nuevo trabajo.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"üòä,üéâ,üíº,üí™\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"No me siento bien, tengo dolor de cabeza.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"üòû,ü§ï,üíî\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"Hoy es un d√≠a incre√≠ble para correr al aire libre.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"üèÉ‚Äç‚ôÇÔ∏è,üå≥,üåû,üí®\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"Acabo de terminar de ver una pel√≠cula emocionante.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"üé¨,üëè,üò±,‚ù§Ô∏è\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"Voy a dormir temprano, me siento agotado.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"üò¥,üõèÔ∏è,üò¥\"},\n",
    "    \n",
    "    # Ahora pedimos la predicci√≥n para el nuevo mensaje\n",
    "    {\"role\": \"user\", \"content\": \"Estoy muy cansado, pero contento con el trabajo que he hecho.\"},\n",
    "]\n",
    "\n",
    "# Llamada a la API para obtener la predicci√≥n de emojis\n",
    "response = client.chat.completions.create(\n",
    "    model=CHAT_COMPLETIONS_MODEL,\n",
    "    messages=few_shot_prompt\n",
    ")\n",
    "\n",
    "# Mostrar la respuesta generada\n",
    "print(response.choices[0].message.content)  # Ejemplo de salida: \"üòÖ,üí™,üëå\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
